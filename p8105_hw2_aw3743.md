P8105 Homework 2
================
Aisha Waggeh
October 1 2025

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1

This problem uses 3 FiveThrityEight datasets:

- `pols-month.csv` – counts of national politicians (governors,
  senators, representatives) by party, and whether the sitting president
  is Republican or Democrat.  
- `snp.csv` – monthly closing values of the S&P stock market index.  
- `unemployment.csv` – monthly unemployment rates from the US Bureau of
  Labor Statistics.

Our goal is to clean and merge these datasets using **year** and
**month** as keys.

*Read the pols data*

``` r
pols_df = read_csv("./data/pols-month.csv")
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
pols_df = janitor::clean_names(pols_df)
```

*Clean the pols data + formart*

``` r
# Clean the pols data
pols_clean = pols_df |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.name[month],
    day = as.integer(day),
    president = ifelse(prez_gop == 1, "gop", "dem")
  ) |>
select( -prez_dem, -prez_gop, -day) |>
 arrange(year, month)  

pols_clean
```

    ## # A tibble: 822 × 9
    ##     year month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 April         23      51     253      23      45     198 dem      
    ##  2  1947 August        23      51     253      23      45     198 dem      
    ##  3  1947 December      24      51     253      23      45     198 dem      
    ##  4  1947 February      23      51     253      23      45     198 dem      
    ##  5  1947 January       23      51     253      23      45     198 dem      
    ##  6  1947 July          23      51     253      23      45     198 dem      
    ##  7  1947 June          23      51     253      23      45     198 dem      
    ##  8  1947 March         23      51     253      23      45     198 dem      
    ##  9  1947 May           23      51     253      23      45     198 dem      
    ## 10  1947 November      24      51     253      23      45     198 dem      
    ## # ℹ 812 more rows

*Read the snp data*

``` r
snp_df = read_csv("./data/snp.csv")
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_df = janitor::clean_names(snp_df)
```

*Clean the snp data + formart*

``` r
snp_clean = snp_df |>
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
    year = as.integer(year),
    # Convert 2-digit year to 4-digit year:
    # Years 50-99 -> 1950-1999, Years 00-49 -> 2000- onwards
    year = ifelse(year >= 50, 1900 + year, 2000 + year),
    month = as.integer(month),
    month = month.name[month],
    day = as.integer(day)
  ) |>
  select(-day) |> # Removing day column since we are merging by month only
  arrange(year, month) |>
  select(year, month, close)

snp_clean
```

    ## # A tibble: 787 × 3
    ##     year month    close
    ##    <dbl> <chr>    <dbl>
    ##  1  1950 April     18.0
    ##  2  1950 August    18.4
    ##  3  1950 December  20.4
    ##  4  1950 February  17.2
    ##  5  1950 January   17.0
    ##  6  1950 July      17.8
    ##  7  1950 June      17.7
    ##  8  1950 March     17.3
    ##  9  1950 May       18.8
    ## 10  1950 November  19.5
    ## # ℹ 777 more rows

*Read the unemployment data*

``` r
unemployment_df = read_csv("./data/unemployment.csv")
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemployment_df = janitor::clean_names(unemployment_df)
```

*Tidy the unemployment data + formart*

``` r
unemployment_clean = unemployment_df |>
  pivot_longer(
    cols = jan:dec,
    names_to = "month", 
    values_to = "unemployment_rate"
  ) |>
  mutate(
    month = str_to_title(month),  # Convert to Title Case
    month = month.name[match(month, month.abb)],  # Match with full month names
    year = as.integer(year)
  ) |>
  select(year, month, unemployment_rate) |>
  arrange(year, month)

unemployment_clean
```

    ## # A tibble: 816 × 3
    ##     year month    unemployment_rate
    ##    <int> <chr>                <dbl>
    ##  1  1948 April                  3.9
    ##  2  1948 August                 3.9
    ##  3  1948 December               4  
    ##  4  1948 February               3.8
    ##  5  1948 January                3.4
    ##  6  1948 July                   3.6
    ##  7  1948 June                   3.6
    ##  8  1948 March                  4  
    ##  9  1948 May                    3.5
    ## 10  1948 November               3.8
    ## # ℹ 806 more rows

*Merge all (pols + snp + unemployment) datasets*

``` r
#Need to make sure that we use consistent data type for my merge
pols_clean_fixed = pols_clean |>
  mutate(month = as.character(month))

snp_clean_fixed = snp_clean |>
  mutate(month = as.character(month))

unemployment_clean_fixed = unemployment_clean |>
  mutate(month = as.character(month))
```

``` r
# Now ready for merge, will merge snp into pols first
merged_data = 
  left_join(pols_clean, snp_clean, by = c("year", "month"))

 # Then merge unemployment into the result
final_data =
  left_join(merged_data, unemployment_clean, by = c("year", "month"))

final_data
```

    ## # A tibble: 822 × 11
    ##     year month   gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 April        23      51     253      23      45     198 dem          NA
    ##  2  1947 August       23      51     253      23      45     198 dem          NA
    ##  3  1947 Decemb…      24      51     253      23      45     198 dem          NA
    ##  4  1947 Februa…      23      51     253      23      45     198 dem          NA
    ##  5  1947 January      23      51     253      23      45     198 dem          NA
    ##  6  1947 July         23      51     253      23      45     198 dem          NA
    ##  7  1947 June         23      51     253      23      45     198 dem          NA
    ##  8  1947 March        23      51     253      23      45     198 dem          NA
    ##  9  1947 May          23      51     253      23      45     198 dem          NA
    ## 10  1947 Novemb…      24      51     253      23      45     198 dem          NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemployment_rate <dbl>

``` r
# Need to check the actual start years for each dataset
print("Pols data start:")
```

    ## [1] "Pols data start:"

``` r
pols_clean |> summarize(min_year = min(year), max_year = max(year))
```

    ## # A tibble: 1 × 2
    ##   min_year max_year
    ##      <int>    <int>
    ## 1     1947     2015

``` r
print("SNP data start:")
```

    ## [1] "SNP data start:"

``` r
snp_clean |> summarize(min_year = min(year), max_year = max(year))
```

    ## # A tibble: 1 × 2
    ##   min_year max_year
    ##      <dbl>    <dbl>
    ## 1     1950     2015

``` r
print("Unemployment data start:")
```

    ## [1] "Unemployment data start:"

``` r
unemployment_clean |> summarize(min_year = min(year), max_year = max(year))
```

    ## # A tibble: 1 × 2
    ##   min_year max_year
    ##      <int>    <int>
    ## 1     1948     2015

``` r
# Checking when SNP data actually begins
snp_clean |> arrange(year) |> head(10)
```

    ## # A tibble: 10 × 3
    ##     year month    close
    ##    <dbl> <chr>    <dbl>
    ##  1  1950 April     18.0
    ##  2  1950 August    18.4
    ##  3  1950 December  20.4
    ##  4  1950 February  17.2
    ##  5  1950 January   17.0
    ##  6  1950 July      17.8
    ##  7  1950 June      17.7
    ##  8  1950 March     17.3
    ##  9  1950 May       18.8
    ## 10  1950 November  19.5

- The pols_clean dataset contains 822 monthly observations of US
  political party control from 1947 to 2015. It tracks the number of
  Republican and Democratic politicians across governors, senators, and
  representatives, along with the sitting president’s party. Each row
  represents the political power distribution for a specific month,
  revealing the political landscape over nearly seven decades.

- The snp dataset contains 787 monthly observations of S&P 500 stock
  market closing values from 1950 to 2015. It tracks the closing price
  of the S&P 500 index for each month, showing the performance of the US
  stock market over six decades. The data reveals long-term trends.

- The unemployment dataset contains 816 monthly observations of US
  unemployment rates from 1948 to 2015. It tracks the monthly
  unemployment percentage, providing a measure of economic health and
  labor market conditions over nearly seven decades. The data shows
  fluctuations in employment levels across different economic cycles and
  historical periods.

- Finally, the merged dataset combines political, financial, and
  economic indicators by joining the three datasets using year and month
  as keys. NA values appear for the unemployment rate in 1947 and for
  S&P closing values from 1947-1949 because these datasets start later
  than the political data (unemployment in 1948, S&P in 1950). The
  resulting dataset contains 822 monthly observations from 1947 to 2015,
  enabling analysis of how political changes correlate with economic
  trends across decades. This comprehensive resource allows us to
  examine relationships between government leadership, stock market
  performance, and labor market conditions over time.

## Problem 2

This problem uses the Mr. Trash Wheel dataset, to read & clean.

``` r
mr_trash_df = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                        sheet = "Mr. Trash Wheel",
                        range = "A2:N655",
                        col_types = "text")

mr_trash_df = janitor::clean_names(mr_trash_df)
```

*Clean the Mr. Trash Wheel data*

``` r
# Clean the data
mr_trash_clean = mr_trash_df |>
  filter(!is.na(dumpster) & !is.na(weight_tons)) |>
  mutate(
    across(c(dumpster, year, weight_tons, volume_cubic_yards), as.numeric),
    across(c(plastic_bottles, polystyrene, cigarette_butts, glass_bottles, 
             plastic_bags, wrappers, sports_balls, homes_powered),  # Now it should be homes_powered
           ~ as.numeric(gsub(",", "", .))),
    date = as.Date(as.numeric(date), origin = "1899-12-30"),
    sports_balls = as.integer(round(sports_balls)),
    trash_wheel = "Mr. Trash Wheel"
  ) |>
  arrange(year, month, dumpster)

mr_trash_clean
```

    ## # A tibble: 651 × 15
    ##    dumpster month     year date       weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <date>           <dbl>              <dbl>
    ##  1       25 August    2014 2014-08-04        4.39                 16
    ##  2       26 August    2014 2014-08-04        5.33                 17
    ##  3       27 August    2014 2014-08-13        3.58                 20
    ##  4       28 August    2014 2014-08-13        3.1                  17
    ##  5       29 August    2014 2014-08-19        1.77                 10
    ##  6       42 December  2014 2014-12-01        1.81                 17
    ##  7       43 December  2014 2014-12-17        3.48                 15
    ##  8       44 December  2014 2014-12-30        3.18                 15
    ##  9       18 July      2014 2014-07-03        2.54                 15
    ## 10       19 July      2014 2014-07-07        2.41                 15
    ## # ℹ 641 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, trash_wheel <chr>

*Read the Professor Trash Wheel data*

``` r
# Read Professor Trash Wheel data with manual column names
prof_trash_df = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                          sheet = "Professor Trash Wheel", 
                          range = "A1:M118",
                          col_names = c("dumpster", "month", "year", "date", "weight_tons",
                                       "volume_cubic_yards", "plastic_bottles", "polystyrene",
                                       "cigarette_butts", "glass_bottles", "plastic_bags", 
                                       "wrappers", "homes_powered"),
                          col_types = "text")

# Remove header row and clean names
prof_trash_df = prof_trash_df |>
  slice(-1) |>
  janitor::clean_names()

print("Cleaned column names:")
```

    ## [1] "Cleaned column names:"

``` r
names(prof_trash_df)
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "glass_bottles"      "plastic_bags"       "wrappers"          
    ## [13] "homes_powered"

*Clean the Professor Trash Wheel data + format*

``` r
# Clean the data using the correct column names
prof_trash_clean = prof_trash_df |>
  filter(!is.na(dumpster) & !is.na(weight_tons)) |>
  mutate(
    across(c(dumpster, year, weight_tons, volume_cubic_yards), as.numeric),
    across(c(plastic_bottles, polystyrene, cigarette_butts, glass_bottles, 
             plastic_bags, wrappers, homes_powered),
           ~ as.numeric(gsub(",", "", .))),
    date = as.Date(as.numeric(date), origin = "1899-12-30"),
    trash_wheel = "Professor Trash Wheel"
  ) |>
  arrange(year, month, dumpster)
```

    ## Warning: There were 12 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `across(c(dumpster, year, weight_tons, volume_cubic_yards),
    ##   as.numeric)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 11 remaining warnings.

``` r
prof_trash_clean
```

    ## # A tibble: 117 × 14
    ##    dumpster month     year date       weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <date>           <dbl>              <dbl>
    ##  1        7 April     2017 2017-04-01        1.82                 15
    ##  2        8 April     2017 2017-04-20        2.37                 15
    ##  3       15 August    2017 2017-08-04        2.93                 15
    ##  4       16 August    2017 2017-08-31        1.21                 15
    ##  5        3 February  2017 2017-02-26        2.32                 18
    ##  6        4 February  2017 2017-02-26        3.72                 15
    ##  7        5 February  2017 2017-02-28        1.45                 15
    ##  8        1 January   2017 2017-01-02        1.79                 15
    ##  9        2 January   2017 2017-01-30        1.58                 15
    ## 10       12 July      2017 2017-07-17        1.63                 15
    ## # ℹ 107 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, trash_wheel <chr>

*Read the Gwynnda Trash Wheel data*

``` r
# Read with correct column names for Gwynnda's actual structure since before x1..... xetc
gwynnda_trash_df_raw = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                                 sheet = "Gwynnda Trash Wheel",
                                 range = "A1:L265",
                                 col_names = c("dumpster", "month", "year", "date", "weight_tons",
                                              "volume_cubic_yards", "plastic_bottles", "polystyrene",
                                              "cigarette_butts", "plastic_bags", "wrappers", 
                                              "homes_powered"),
                                 col_types = "text")

print("Column names:")
```

    ## [1] "Column names:"

``` r
print(names(gwynnda_trash_df_raw))
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "plastic_bags"       "wrappers"           "homes_powered"

``` r
# Now process
gwynnda_trash_df = gwynnda_trash_df_raw |>
  slice(-1) |>  # Remove the header row
  janitor::clean_names()

print("Cleaned column names:")
```

    ## [1] "Cleaned column names:"

``` r
print(names(gwynnda_trash_df))
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "plastic_bags"       "wrappers"           "homes_powered"

*Clean the Gwynnda*

``` r
# Clean the data
gwynnda_trash_clean = gwynnda_trash_df |>
  filter(!is.na(dumpster) & !is.na(weight_tons)) |>
  mutate(
    # Convert all numeric columns with better handling
    across(c(dumpster, year, weight_tons, volume_cubic_yards, 
             plastic_bottles, polystyrene, cigarette_butts,
             plastic_bags, wrappers, homes_powered),
           ~ {
             # Remove commas and convert to numeric, handling empty strings
             clean_val = gsub(",", "", .)
             # Convert empty strings to NA before numeric conversion
             clean_val[clean_val == ""] <- NA
             as.numeric(clean_val)
           }),
    date = as.Date(as.numeric(date), origin = "1899-12-30"),
    trash_wheel = "Gwynnda Trash Wheel"
  ) |>
  arrange(year, month, dumpster)
```

    ## Warning: There were 11 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `across(...)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 10 remaining warnings.

``` r
gwynnda_trash_clean
```

    ## # A tibble: 264 × 13
    ##    dumpster month   year date       weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <date>           <dbl>              <dbl>
    ##  1        6 August  2021 2021-08-11        2.06                 15
    ##  2        7 August  2021 2021-08-14        1.9                  15
    ##  3        8 August  2021 2021-08-16        2.16                 15
    ##  4        9 August  2021 2021-08-16        2.6                  15
    ##  5       10 August  2021 2021-08-17        3.21                 15
    ##  6       11 August  2021 2021-08-17        2.44                 15
    ##  7       12 August  2021 2021-08-18        2.62                 15
    ##  8       13 August  2021 2021-08-19        2.92                 15
    ##  9       14 August  2021 2021-08-19        2.93                 15
    ## 10       15 August  2021 2021-08-20        3.31                 15
    ## # ℹ 254 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, trash_wheel <chr>

*Now we can combine all the 3 data sets*

``` r
all_trash_wheels = bind_rows(mr_trash_clean, prof_trash_clean, gwynnda_trash_clean) |>
  arrange(year, month, dumpster)

all_trash_wheels
```

    ## # A tibble: 1,032 × 15
    ##    dumpster month     year date       weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <date>           <dbl>              <dbl>
    ##  1       25 August    2014 2014-08-04        4.39                 16
    ##  2       26 August    2014 2014-08-04        5.33                 17
    ##  3       27 August    2014 2014-08-13        3.58                 20
    ##  4       28 August    2014 2014-08-13        3.1                  17
    ##  5       29 August    2014 2014-08-19        1.77                 10
    ##  6       42 December  2014 2014-12-01        1.81                 17
    ##  7       43 December  2014 2014-12-17        3.48                 15
    ##  8       44 December  2014 2014-12-30        3.18                 15
    ##  9       18 July      2014 2014-07-03        2.54                 15
    ## 10       19 July      2014 2014-07-07        2.41                 15
    ## # ℹ 1,022 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, trash_wheel <chr>

*Answering the specific questions for Problem 2*

``` r
# Total weight of trash collected by Professor Trash Wheel
prof_total_weight = all_trash_wheels |>
  filter(trash_wheel == "Professor Trash Wheel") |>
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))

# Total cigarette butts collected by Gwynnda in June 2022
gwynnda_june_2022 = all_trash_wheels |>
  filter(trash_wheel == "Gwynnda Trash Wheel",
         year == 2022,
         month == "June") |>
  summarize(total_cigarettes = sum(cigarette_butts, na.rm = TRUE))

prof_total_weight
```

    ## # A tibble: 1 × 1
    ##   total_weight
    ##          <dbl>
    ## 1         241.

``` r
gwynnda_june_2022
```

    ## # A tibble: 1 × 1
    ##   total_cigarettes
    ##              <dbl>
    ## 1            18120

*Dataset Summary*

``` r
# Check the actual column names in the combined dataset
print("Column names in all_trash_wheels:")
```

    ## [1] "Column names in all_trash_wheels:"

``` r
names(all_trash_wheels)
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "glass_bottles"      "plastic_bags"       "wrappers"          
    ## [13] "sports_balls"       "homes_powered"      "trash_wheel"

``` r
# Check if any column names are empty
print("Any empty column names?")
```

    ## [1] "Any empty column names?"

``` r
any(names(all_trash_wheels) == "")
```

    ## [1] FALSE

``` r
# Check the structure of the dataset
print("Dataset structure:")
```

    ## [1] "Dataset structure:"

``` r
glimpse(all_trash_wheels)
```

    ## Rows: 1,032
    ## Columns: 15
    ## $ dumpster           <dbl> 25, 26, 27, 28, 29, 42, 43, 44, 18, 19, 20, 21, 22,…
    ## $ month              <chr> "August", "August", "August", "August", "August", "…
    ## $ year               <dbl> 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 201…
    ## $ date               <date> 2014-08-04, 2014-08-04, 2014-08-13, 2014-08-13, 20…
    ## $ weight_tons        <dbl> 4.39, 5.33, 3.58, 3.10, 1.77, 1.81, 3.48, 3.18, 2.5…
    ## $ volume_cubic_yards <dbl> 16, 17, 20, 17, 10, 17, 15, 15, 15, 15, 18, 15, 16,…
    ## $ plastic_bottles    <dbl> 2140, 1630, 3640, 1430, 570, 1370, 550, 640, 1640, …
    ## $ polystyrene        <dbl> 2050, 1950, 4360, 1870, 780, 3140, 1450, 1670, 1960…
    ## $ cigarette_butts    <dbl> 118000, 123000, 141000, 121000, 32000, 38000, 22000…
    ## $ glass_bottles      <dbl> 68, 75, 82, 63, 21, 28, 34, 42, 65, 63, 79, 32, 53,…
    ## $ plastic_bags       <dbl> 904, 512, 1560, 552, 310, 950, 740, 880, 744, 896, …
    ## $ wrappers           <dbl> 1762, 1318, 3067, 1144, 1440, 1620, 1280, 1540, 132…
    ## $ sports_balls       <int> 6, 7, 8, 7, 4, 7, 6, 6, 6, 6, 7, 6, 6, 6, 5, 6, 7, …
    ## $ homes_powered      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
    ## $ trash_wheel        <chr> "Mr. Trash Wheel", "Mr. Trash Wheel", "Mr. Trash Wh…

``` r
#Now we can do a dataset summary to see what is happening 
trash_summary = tibble(
  n_rows = nrow(all_trash_wheels),
  n_cols = ncol(all_trash_wheels),
  min_year = min(all_trash_wheels$year, na.rm = TRUE),
  max_year = max(all_trash_wheels$year, na.rm = TRUE),
  key_variables = paste(names(all_trash_wheels), collapse = ", ")
)

# Check Professor Trash Wheel total weight
prof_total_weight = all_trash_wheels |>
  filter(trash_wheel == "Professor Trash Wheel") |>
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))

prof_total_weight
```

    ## # A tibble: 1 × 1
    ##   total_weight
    ##          <dbl>
    ## 1         241.

``` r
trash_summary
```

    ## # A tibble: 1 × 5
    ##   n_rows n_cols min_year max_year key_variables                                 
    ##    <int>  <int>    <dbl>    <dbl> <chr>                                         
    ## 1   1032     15     2014     2024 dumpster, month, year, date, weight_tons, vol…

- The combined Trash Wheel dataset contains 1,031 observations and 15
  columns, covering the period from 2014 to 2024. The dataset tracks
  trash collection from three water-cleaning devices: Mr. Trash Wheel,
  Professor Trash Wheel, and Gwynnda. Key variables include dumpster
  number, month, year, weight in tons, volume in cubic yards, and counts
  of specific trash types like plastic bottles, cigarette butts, and
  sports balls. Professor Trash Wheel collected a total of 243.4 tons of
  trash, while Gwynnda collected 18,120 cigarette butts in June 2022.

## Problem 3

*Read and clean the ZORI Dataset*

``` r
# Read ZORI data with manual column name handling
zori_df = read_csv("./data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", 
                  col_names = TRUE,
                  show_col_types = FALSE)

# Manually assign clean names to first 9 columns
clean_names_first9 <- c("region_id", "size_rank", "region_name", "region_type", 
                       "state_name", "state", "city", "metro", "county_name")
names(zori_df)[1:9] <- clean_names_first9

# Pivot longer and convert date columns
zori_clean = zori_df |>
  pivot_longer(
    cols = 10:ncol(zori_df),  # Date columns
    names_to = "date_str",
    values_to = "rental_price"
  ) |>
  mutate(
    # date_str is already in "YYYY-MM-DD" format, use it directly
    date = as.Date(date_str),
    year = year(date),
    month = month(date, label = TRUE),
    month_num = month(date)
  ) |>
  filter(!is.na(rental_price)) |>
  rename(zip_code = region_name) |>
  arrange(zip_code, date)

zori_clean
```

    ## # A tibble: 10,450 × 15
    ##    region_id size_rank zip_code region_type state_name state city     metro     
    ##        <dbl>     <dbl>    <dbl> <chr>       <chr>      <chr> <chr>    <chr>     
    ##  1     61615      4444    10001 zip         NY         NY    New York New York-…
    ##  2     61615      4444    10001 zip         NY         NY    New York New York-…
    ##  3     61615      4444    10001 zip         NY         NY    New York New York-…
    ##  4     61615      4444    10001 zip         NY         NY    New York New York-…
    ##  5     61615      4444    10001 zip         NY         NY    New York New York-…
    ##  6     61615      4444    10001 zip         NY         NY    New York New York-…
    ##  7     61615      4444    10001 zip         NY         NY    New York New York-…
    ##  8     61615      4444    10001 zip         NY         NY    New York New York-…
    ##  9     61615      4444    10001 zip         NY         NY    New York New York-…
    ## 10     61615      4444    10001 zip         NY         NY    New York New York-…
    ## # ℹ 10,440 more rows
    ## # ℹ 7 more variables: county_name <chr>, date_str <chr>, rental_price <dbl>,
    ## #   date <date>, year <dbl>, month <ord>, month_num <dbl>

*Read and clean the ZIP Codes data set*

``` r
# Read ZIP code data
zip_df = read_csv("./data/Zip Codes.csv")
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
zip_df = janitor::clean_names(zip_df)

# Clean ZIP code data
zip_clean = zip_df |>
  mutate(
    zip_code = as.character(zip_code),
    borough = county
  ) |>
  select(zip_code, borough, neighborhood) |>
  filter(!is.na(zip_code)) |>
  distinct()

zip_clean
```

    ## # A tibble: 322 × 3
    ##    zip_code borough neighborhood              
    ##    <chr>    <chr>   <chr>                     
    ##  1 10451    Bronx   High Bridge and Morrisania
    ##  2 10452    Bronx   High Bridge and Morrisania
    ##  3 10453    Bronx   Central Bronx             
    ##  4 10454    Bronx   Hunts Point and Mott Haven
    ##  5 10455    Bronx   Hunts Point and Mott Haven
    ##  6 10456    Bronx   High Bridge and Morrisania
    ##  7 10457    Bronx   Central Bronx             
    ##  8 10458    Bronx   Bronx Park and Fordham    
    ##  9 10459    Bronx   Hunts Point and Mott Haven
    ## 10 10460    Bronx   Central Bronx             
    ## # ℹ 312 more rows

*Now merge the 2 datasets*

``` r
# I kept getting an error for the zip-code file
# Converting zip_code to character and overwrite the my data set
zori_clean = zori_clean |>
  mutate(zip_code = as.character(zip_code))

# Verify the conversion worked
print("ZORI zip_code type after conversion:")
```

    ## [1] "ZORI zip_code type after conversion:"

``` r
class(zori_clean$zip_code)
```

    ## [1] "character"

``` r
print("ZORI zip_code sample after conversion:")
```

    ## [1] "ZORI zip_code sample after conversion:"

``` r
head(zori_clean$zip_code)
```

    ## [1] "10001" "10001" "10001" "10001" "10001" "10001"

``` r
# Now merge the datasets
final_rental_data = zori_clean |>
  left_join(zip_clean, by = "zip_code")
```

    ## Warning in left_join(zori_clean, zip_clean, by = "zip_code"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 5205 of `x` matches multiple rows in `y`.
    ## ℹ Row 79 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

``` r
final_rental_data
```

    ## # A tibble: 10,677 × 17
    ##    region_id size_rank zip_code region_type state_name state city     metro     
    ##        <dbl>     <dbl> <chr>    <chr>       <chr>      <chr> <chr>    <chr>     
    ##  1     61615      4444 10001    zip         NY         NY    New York New York-…
    ##  2     61615      4444 10001    zip         NY         NY    New York New York-…
    ##  3     61615      4444 10001    zip         NY         NY    New York New York-…
    ##  4     61615      4444 10001    zip         NY         NY    New York New York-…
    ##  5     61615      4444 10001    zip         NY         NY    New York New York-…
    ##  6     61615      4444 10001    zip         NY         NY    New York New York-…
    ##  7     61615      4444 10001    zip         NY         NY    New York New York-…
    ##  8     61615      4444 10001    zip         NY         NY    New York New York-…
    ##  9     61615      4444 10001    zip         NY         NY    New York New York-…
    ## 10     61615      4444 10001    zip         NY         NY    New York New York-…
    ## # ℹ 10,667 more rows
    ## # ℹ 9 more variables: county_name <chr>, date_str <chr>, rental_price <dbl>,
    ## #   date <date>, year <dbl>, month <ord>, month_num <dbl>, borough <chr>,
    ## #   neighborhood <chr>

``` r
# Check the column names in the merged dataset
print("Column names in final_rental_data:")
```

    ## [1] "Column names in final_rental_data:"

``` r
names(final_rental_data)
```

    ##  [1] "region_id"    "size_rank"    "zip_code"     "region_type"  "state_name"  
    ##  [6] "state"        "city"         "metro"        "county_name"  "date_str"    
    ## [11] "rental_price" "date"         "year"         "month"        "month_num"   
    ## [16] "borough"      "neighborhood"

``` r
# Check if any column names are empty
print("Empty column names:")
```

    ## [1] "Empty column names:"

``` r
any(names(final_rental_data) == "")
```

    ## [1] FALSE

``` r
# Check the structure
print("Dataset structure:")
```

    ## [1] "Dataset structure:"

``` r
glimpse(final_rental_data)
```

    ## Rows: 10,677
    ## Columns: 17
    ## $ region_id    <dbl> 61615, 61615, 61615, 61615, 61615, 61615, 61615, 61615, 6…
    ## $ size_rank    <dbl> 4444, 4444, 4444, 4444, 4444, 4444, 4444, 4444, 4444, 444…
    ## $ zip_code     <chr> "10001", "10001", "10001", "10001", "10001", "10001", "10…
    ## $ region_type  <chr> "zip", "zip", "zip", "zip", "zip", "zip", "zip", "zip", "…
    ## $ state_name   <chr> "NY", "NY", "NY", "NY", "NY", "NY", "NY", "NY", "NY", "NY…
    ## $ state        <chr> "NY", "NY", "NY", "NY", "NY", "NY", "NY", "NY", "NY", "NY…
    ## $ city         <chr> "New York", "New York", "New York", "New York", "New York…
    ## $ metro        <chr> "New York-Newark-Jersey City, NY-NJ-PA", "New York-Newark…
    ## $ county_name  <chr> "New York County", "New York County", "New York County", …
    ## $ date_str     <chr> "2015-01-31", "2015-02-28", "2015-03-31", "2015-04-30", "…
    ## $ rental_price <dbl> 3855.089, 3892.376, 3898.212, 3969.644, 4033.221, 4070.80…
    ## $ date         <date> 2015-01-31, 2015-02-28, 2015-03-31, 2015-04-30, 2015-05-…
    ## $ year         <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 201…
    ## $ month        <ord> Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, De…
    ## $ month_num    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, …
    ## $ borough      <chr> "New York", "New York", "New York", "New York", "New York…
    ## $ neighborhood <chr> "Chelsea and Clinton", "Chelsea and Clinton", "Chelsea an…

``` r
# Create summary using the direct approach
total_obs = nrow(final_rental_data)
unique_zips = n_distinct(final_rental_data$zip_code)
unique_neighborhoods = n_distinct(final_rental_data$neighborhood)
min_date = min(final_rental_data$date)
max_date = max(final_rental_data$date)

dataset_summary = tibble(
  total_observations = total_obs,
  unique_zip_codes = unique_zips,
  unique_neighborhoods = unique_neighborhoods,
  date_range = paste(min_date, "to", max_date)
)

dataset_summary
```

    ## # A tibble: 1 × 4
    ##   total_observations unique_zip_codes unique_neighborhoods date_range           
    ##                <int>            <int>                <int> <chr>                
    ## 1              10677              149                   43 2015-01-31 to 2024-0…

*Identify Zip Codes missing from ZORI data*

``` r
# ZIP codes in ZIP dataset but not in ZORI
missing_zips = zip_clean |>
  anti_join(zori_clean, by = "zip_code")

missing_zips_count = nrow(missing_zips)

print(paste("ZIP codes missing from ZORI data:", missing_zips_count))
```

    ## [1] "ZIP codes missing from ZORI data: 171"

``` r
# Count by borough
missing_by_borough = missing_zips |>
  count(borough, name = "missing_count") |>
  arrange(desc(missing_count))

print("Missing ZIP codes by borough:")
```

    ## [1] "Missing ZIP codes by borough:"

``` r
missing_by_borough
```

    ## # A tibble: 5 × 2
    ##   borough  missing_count
    ##   <chr>            <int>
    ## 1 New York           102
    ## 2 Queens              44
    ## 3 Kings               11
    ## 4 Bronx                8
    ## 5 Richmond             6

``` r
# Show sample of missing ZIP codes
missing_sample = missing_zips |>
  head(10)

print("Sample of missing ZIP codes:")
```

    ## [1] "Sample of missing ZIP codes:"

``` r
missing_sample
```

    ## # A tibble: 10 × 3
    ##    zip_code borough neighborhood              
    ##    <chr>    <chr>   <chr>                     
    ##  1 10464    Bronx   Southeast Bronx           
    ##  2 10474    Bronx   Hunts Point and Mott Haven
    ##  3 10475    Bronx   Northeast Bronx           
    ##  4 10499    Bronx   <NA>                      
    ##  5 10550    Bronx   <NA>                      
    ##  6 10704    Bronx   <NA>                      
    ##  7 10705    Bronx   <NA>                      
    ##  8 10803    Bronx   <NA>                      
    ##  9 11202    Kings   <NA>                      
    ## 10 11224    Kings   Southern Brooklyn

``` r
# Summary of missing ZIP codes by borough
missing_summary = missing_zips |>
  group_by(borough) |>
  summarize(missing_count = n()) |>
  arrange(desc(missing_count))

missing_summary
```

    ## # A tibble: 5 × 2
    ##   borough  missing_count
    ##   <chr>            <int>
    ## 1 New York           102
    ## 2 Queens              44
    ## 3 Kings               11
    ## 4 Bronx                8
    ## 5 Richmond             6

``` r
# Get the list of boroughs with missing ZIP codes
missing_boroughs = missing_summary$borough
```

*COVID-19 rental price comparison*

``` r
# Only following approach works on my end
jan_2020 = final_rental_data |>
  filter(month_num == 1, year == 2020) |>
  select(zip_code, borough, neighborhood, rental_price_2020 = rental_price)

jan_2021 = final_rental_data |>
  filter(month_num == 1, year == 2021) |>
  select(zip_code, rental_price_2021 = rental_price)

# Join and calculate changes
covid_comparison = jan_2020 |>
  inner_join(jan_2021, by = "zip_code") |>
  mutate(
    price_change = rental_price_2021 - rental_price_2020,
    percent_change = (rental_price_2021 - rental_price_2020) / rental_price_2020 * 100
  )
```

    ## Warning in inner_join(jan_2020, jan_2021, by = "zip_code"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 45 of `x` matches multiple rows in `y`.
    ## ℹ Row 48 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

``` r
# Top 10 largest price drops
top_drops = covid_comparison |>
  arrange(price_change) |>
  head(10)

print("Top 10 largest price drops (Jan 2020 to Jan 2021):")
```

    ## [1] "Top 10 largest price drops (Jan 2020 to Jan 2021):"

``` r
top_drops
```

    ## # A tibble: 10 × 7
    ##    zip_code borough  neighborhood            rental_price_2020 rental_price_2021
    ##    <chr>    <chr>    <chr>                               <dbl>             <dbl>
    ##  1 10007    New York Lower Manhattan                     6334.             5422.
    ##  2 10069    New York <NA>                                4623.             3875.
    ##  3 10009    New York Lower East Side                     3406.             2692.
    ##  4 10016    New York Gramercy Park and Murr…             3731.             3019.
    ##  5 10001    New York Chelsea and Clinton                 4108.             3398.
    ##  6 10002    New York Lower East Side                     3645.             2935.
    ##  7 10004    New York Lower Manhattan                     3150.             2444.
    ##  8 10038    New York Lower Manhattan                     3573.             2876.
    ##  9 10012    New York Greenwich Village and …             3629.             2942.
    ## 10 10010    New York Gramercy Park and Murr…             3697.             3012.
    ## # ℹ 2 more variables: price_change <dbl>, percent_change <dbl>

``` r
# Get the range of percentage drops
min_pct_drop = round(min(top_drops$percent_change), 1)
max_pct_drop = round(max(top_drops$percent_change), 1)

# Got boroughs represented in top drops
top_drop_boroughs = unique(top_drops$borough)

print(paste("Percentage drop range:", min_pct_drop, "% to", max_pct_drop, "%"))
```

    ## [1] "Percentage drop range: -22.4 % to -14.4 %"

``` r
print(paste("Boroughs with largest drops:", paste(top_drop_boroughs, collapse = ", ")))
```

    ## [1] "Boroughs with largest drops: New York"

``` r
# Show the complete top 10 drops
top_drops_complete = covid_comparison |>
  arrange(price_change) |>
  head(10)

print("Complete top 10 largest price drops:")
```

    ## [1] "Complete top 10 largest price drops:"

``` r
top_drops_complete
```

    ## # A tibble: 10 × 7
    ##    zip_code borough  neighborhood            rental_price_2020 rental_price_2021
    ##    <chr>    <chr>    <chr>                               <dbl>             <dbl>
    ##  1 10007    New York Lower Manhattan                     6334.             5422.
    ##  2 10069    New York <NA>                                4623.             3875.
    ##  3 10009    New York Lower East Side                     3406.             2692.
    ##  4 10016    New York Gramercy Park and Murr…             3731.             3019.
    ##  5 10001    New York Chelsea and Clinton                 4108.             3398.
    ##  6 10002    New York Lower East Side                     3645.             2935.
    ##  7 10004    New York Lower Manhattan                     3150.             2444.
    ##  8 10038    New York Lower Manhattan                     3573.             2876.
    ##  9 10012    New York Greenwich Village and …             3629.             2942.
    ## 10 10010    New York Gramercy Park and Murr…             3697.             3012.
    ## # ℹ 2 more variables: price_change <dbl>, percent_change <dbl>

``` r
# Get the range of percentage drops
min_pct_drop = round(min(top_drops_complete$percent_change), 1)
max_pct_drop = round(max(top_drops_complete$percent_change), 1)

# Get boroughs represented in top drops
top_drop_boroughs = unique(top_drops_complete$borough)

print(paste("Percentage drop range:", min_pct_drop, "% to", max_pct_drop, "%"))
```

    ## [1] "Percentage drop range: -22.4 % to -14.4 %"

``` r
print(paste("Boroughs with largest drops:", paste(top_drop_boroughs, collapse = ", ")))
```

    ## [1] "Boroughs with largest drops: New York"

*Answer to Problem 3*

- The combined rental dataset contains 10,677 observations tracking
  prices across 149 ZIP codes and 43 NYC neighborhoods from 2015-2024.
  Analysis reveals 171 ZIP codes are missing from the rental data,
  primarily from Manhattan (102) and Queens (44), likely representing
  commercial or low-rental areas. During COVID-19, the largest price
  drops ranged from 14.4% to 22.4%, all concentrated in Manhattan
  neighborhoods. Lower Manhattan, Chelsea, and the Lower East Side
  experienced the most severe declines due to pandemic-related migration
  from dense urban centers. The dataset captures both the initial
  pandemic shock and subsequent recovery through 2024.
